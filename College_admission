setwd("C:/Users/PranaliChindarkar/Desktop/Data_Sci/R/R_practice/")
getwd()

#load and verify the data set
data1 <- read.csv("College_Admission.csv")
View(data1)
str(data1)

#convert admit from int to factor
data1$admit <- sapply(data1$admit, factor)
str(data1)

#check for missing value
sapply(data1, function(x) sum(is.na(x)))# no missing value.

# Check for outlier
boxplot(data1)

#treating the outlier variable gre 
boxplot(data1$gre, plot= FALSE)$out

#removing the outlier 
outlier <- boxplot(data1$gre,plot= FALSE)$out
outlier

new_data <- data1[-which(data1$gre %in% outlier),]
summary(new_data$gre)
boxplot(new_data$gre)
boxplot(new_data)

#treating the outlier variable gpa
boxplot(new_data$gpa, plot= FALSE)$out

#removing the outlier 
outlier <- boxplot(new_data$gpa,plot= FALSE)$out
outlier

new_data1 <- new_data[-which(new_data$gpa %in% outlier),]
summary(new_data1$gpa)
boxplot(new_data1$gpa)
boxplot(new_data1)

#convert gre score into categories
new_data1$gre_category <- ifelse(new_data1$gre < 440, 1,ifelse(new_data1$gre < 580 & new_data1$gre > 440,2,3))
table(new_data1$gre_category)
View(new_data1)

new_data1 <- new_data1[,c("admit","gpa","ses","Gender_Male","Race","rank","gre_category")]
new_data1[1:3,]
summary(new_data1)

#check gpa score and rank is normaliy distributed or not
library(moments)
print(kurtosis(new_data1$gpa))
hist(new_data1$gpa)

print(kurtosis(new_data1$rank))
hist(new_data1$rank)

#normalizing data
library(caret)
ss <- preProcess(as.data.frame(new_data1),method = c("range"))
new_data1 <- predict(ss, as.data.frame(new_data1))
new_data1[1:3,]

#import necessary libraries
library(ggplot2)
library(cowplot)

#correlation between gpa and Race/gre
x <- ggplot(new_data1, aes(gpa, Race)) +
  geom_jitter(color = "blue", alpha = 0.5) +
  theme_light()

y <- ggplot(new_data1, aes(gpa, gre_category)) +
  geom_jitter(color = "green", alpha = 0.5) +
  theme_light()

p <- plot_grid(x, y) 
title <- ggdraw() + draw_label("1. Correlation between gpa and Race / gre_category", fontface='bold')
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1))

#correlation between gender_male and gre also race and rank
x <- ggplot(new_data1, aes(Gender_Male, gre_category)) +
  geom_jitter(aes(color = Gender_Male), alpha = 0.7) +
  theme_light()

y <- ggplot(new_data1, aes(Race, rank)) +
  geom_jitter(aes(color = Race), alpha = 0.7) +
  theme_light()

p <- plot_grid(x, y) 
title <- ggdraw() + draw_label("2. Correlation b/w Gender_Male & gre_category , Race & rank" ", fontface='bold')
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1))

#split the data
sample_split <- floor(.7 * nrow(new_data1))
set.seed(1)
training <- sample(seq_len(nrow(new_data1)),size=sample_split)
admission_train <- new_data1[training,]
admission_test <- new_data1[-training,]

# loading packages
library(caTools)
library(ROCR)
library(dplyr)
library(caret)
library(ISLR)
library(InformationValue)
library(tidyverse)

# training logistic regression model
logistic_model <- glm(admit~., data = admission_train,family = "binomial")
summary(logistic_model)

#test data
Prediction <- predict(logistic_model, admission_test, type="response")

#changing probabilities
predict_reg <- ifelse(Prediction >0.5, 1, 0)

#confusion matrix
confusionMatrix(admission_test$admit, predict_reg)

#check accuracy
missing_classerr <- mean(predict_reg != admission_test$admit)
print(paste('Accuracy =', 1 - missing_classerr))

#ROC-AUC curve
ROCPred <- prediction(predict_reg, admission_test$admit) 
ROCPer <- performance(ROCPred, measure = "tpr", x.measure = "fpr")

auc <- performance(ROCPred, measure = "auc")
auc <- auc@y.values[[1]]
auc

#plotting curve
plot(ROCPer)
plot(ROCPer, colorize = TRUE, print.cutoffs.at = seq(0.1, by = 0.1),  main = "ROC CURVE")
abline(a = 0, b = 1)

auc <- round(auc, 4)
legend(.6, .4, auc, title = "AUC", cex = 1)
#Accuracy with logistic regression model is 69 % with AUC 0.54

library(mlbench)
library(rpart)
library(rpart.plot)

#build the model for Decision Tree
tree_model <- rpart(admit~., data=admission_train, method ="class")
rpart.plot(tree_model, extra=106)
tree_model

#analyze results
printcp(tree_model)
plotcp(tree_model)
summary(tree_model)

#confusion matrix
predic_model <- predict(tree_model, admission_test, type = 'class')
table_mat <- table(admission_test$admit, predic_model)
table_mat

#accuracy
accuracy_t <- sum(diag(table_mat))/sum(table_mat)
accuracy_t

#accuracy of decision tree model is 64%

library(e1071)

#Support Vector Machine(SVM)
svm_model <- svm(admit~., admission_train)
summary(svm_model)

#changing probabilities
predict_reg <- ifelse(Prediction >0.5, 1, 0)

#confusion matrix
confusionMatrix(admission_test$admit, predict_reg)

#check accuracy
missing_classerr <- mean(predict_reg != admission_test$admit)
print(paste('Accuracy =', 1 - missing_classerr))

#Accuracy with SVM is 69%
